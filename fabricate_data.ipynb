{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lib import fabricate, analyze, preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import block_diag"
   ],
   "id": "803fb3bdc565d6a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = fabricate.fabricate_base_data()",
   "id": "fc552875590a5a0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng(seed=42)  # reproducibility\n",
    "\n",
    "# Step 1: Keep your existing stats_list\n",
    "stats_list = [\n",
    "    (10, 5, 0, 30, \"continuous\"),   # Recharge Frequency (per month)\n",
    "    (2000, 1000, 200, 5000, \"continuous\"), # Utility Bills (per month)\n",
    "    (3, 2, 0, 10, \"continuous\"),    # International Transactions\n",
    "    (2, 2, 0, 12, \"continuous\"),    # UPI Failures\n",
    "    (1, 1, 0, 5, \"continuous\"),     # Registered Vehicles\n",
    "    (2, 1, 0, 10, \"continuous\"),    # Registered Vehicles Challan (per year)\n",
    "    (2, 1, 0, 5, \"continuous\"),     # Insurances\n",
    "    (2, 1, 0, 10, \"continuous\"),    # Trading Accounts\n",
    "    (3, 2, 0, 10, \"continuous\"),    # Licenses\n",
    "    (1, 1, 0, 5, \"continuous\"),     # FDs Dissolved\n",
    "    (3, 2, 0, 10, \"continuous\"),    # Accounts\n",
    "    (4, 3, 0, 12, \"continuous\"),    # Public Memberships\n",
    "    (1, 1, 0, 4, \"continuous\"),     # Default in GST filing (per quarter)\n",
    "    (5, 3, 0, 20, \"continuous\"),    # VPN Usage (hours per week)\n",
    "    (1, 1, 0, 5, \"continuous\"),     # SIM Card Changes\n",
    "    (4, 2, 0, 10, \"continuous\"),    # Streaming Services\n",
    "    (15, 10, 0, 60, \"continuous\"),  # Payment Delay of Streaming Services (days/year)\n",
    "    (2, 2, 0, 8, \"continuous\"),     # Smart Cards\n",
    "    (2, 1, 0, 5, \"continuous\"),     # Antivirus Subscriptions\n",
    "    (3, 2, 0, 10, \"continuous\"),    # Shopping Behavior (returns/month)\n",
    "    (5000, 2000, 500, 15000, \"continuous\"), # Medical Bills (per year)\n",
    "    (3, 2, 0, 10, \"continuous\"),    # Certificates\n",
    "    (2000, 1500, 200, 10000, \"continuous\"), # Pet Bills (per year)\n",
    "    (2, 1, 0, 6, \"continuous\")      # Dependents\n",
    "]\n",
    "\n",
    "numeric_columns = [\n",
    "    \"Recharge Frequency (per month)\",\n",
    "    \"Utility Bills (per month)\",\n",
    "    \"International Transactions\",\n",
    "    \"UPI Failures\",\n",
    "    \"Registered Vehicles\",\n",
    "    \"Registered Vehicles Challan (per year)\",\n",
    "    \"Insurances\",\n",
    "    \"Trading Accounts\",\n",
    "    \"Licenses\",\n",
    "    \"FDs Dissolved\",\n",
    "    \"Accounts\",\n",
    "    \"Public Memberships\",\n",
    "    \"Default in GST filing (per quarter)\",\n",
    "    \"VPN Usage (hours per week)\",\n",
    "    \"SIM Card Changes\",\n",
    "    \"Streaming Services\",\n",
    "    \"Payment Delay of Streaming Services (days/year)\",\n",
    "    \"Smart Cards\",\n",
    "    \"Antivirus Subscriptions\",\n",
    "    \"Shopping Behavior (returns/month)\",\n",
    "    \"Medical Bills (per year)\",\n",
    "    \"Certificates\",\n",
    "    \"Pet Bills (per year)\",\n",
    "    \"Dependents\"\n",
    "]\n",
    "\n",
    "# Step 2: Block correlation matrices\n",
    "corr_payment_spending = np.array([\n",
    "    [1.0, 0.45, 0.35, 0.30],\n",
    "    [0.45, 1.0, 0.40, 0.33],\n",
    "    [0.35, 0.40, 1.0, 0.38],\n",
    "    [0.30, 0.33, 0.38, 1.0]\n",
    "])\n",
    "\n",
    "corr_asset_ownership = np.array([\n",
    "    [1.0, 0.50, 0.40],\n",
    "    [0.50, 1.0, 0.45],\n",
    "    [0.40, 0.45, 1.0]\n",
    "])\n",
    "\n",
    "corr_fin_accounts = np.array([\n",
    "    [1.0, 0.42, 0.30, 0.35],\n",
    "    [0.42, 1.0, 0.38, 0.33],\n",
    "    [0.30, 0.38, 1.0, 0.40],\n",
    "    [0.35, 0.33, 0.40, 1.0]\n",
    "])\n",
    "\n",
    "corr_compliance_membership = np.array([\n",
    "    [1.0, 0.28],\n",
    "    [0.28, 1.0]\n",
    "])\n",
    "\n",
    "corr_digital = np.array([\n",
    "    [1.0, 0.45, 0.35, 0.30, 0.25, 0.20],\n",
    "    [0.45, 1.0, 0.32, 0.28, 0.26, 0.24],\n",
    "    [0.35, 0.32, 1.0, 0.40, 0.30, 0.22],\n",
    "    [0.30, 0.28, 0.40, 1.0, 0.33, 0.26],\n",
    "    [0.25, 0.26, 0.30, 0.33, 1.0, 0.28],\n",
    "    [0.20, 0.24, 0.22, 0.26, 0.28, 1.0]\n",
    "])\n",
    "\n",
    "corr_ecommerce = np.array([\n",
    "    [1.0, 0.38, 0.35, 0.30],\n",
    "    [0.38, 1.0, 0.36, 0.32],\n",
    "    [0.35, 0.36, 1.0, 0.33],\n",
    "    [0.30, 0.32, 0.33, 1.0]\n",
    "])\n",
    "\n",
    "corr_other = np.array([[1.0]])\n",
    "\n",
    "# Step 3: Combine into full block diagonal matrix\n",
    "correlation_matrix = block_diag(\n",
    "    corr_payment_spending,\n",
    "    corr_asset_ownership,\n",
    "    corr_fin_accounts,\n",
    "    corr_compliance_membership,\n",
    "    corr_digital,\n",
    "    corr_ecommerce,\n",
    "    corr_other\n",
    ")\n",
    "\n",
    "# Step 4: Generate correlated standard normal data\n",
    "n = 10000\n",
    "L = np.linalg.cholesky(correlation_matrix)\n",
    "uncorrelated = rng.normal(size=(n, correlation_matrix.shape[0]))\n",
    "correlated = uncorrelated @ L.T\n",
    "\n",
    "# Step 5: Scale each variable to match stats_list\n",
    "scaled_data = []\n",
    "for i, (mean, std, min_val, max_val, _) in enumerate(stats_list):\n",
    "    col = correlated[:, i]\n",
    "    col = (col - np.mean(col)) / np.std(col)  # standardize\n",
    "    col = col * std + mean  # scale to desired mean/std\n",
    "    col = np.clip(col, min_val, max_val)  # clip to min/max\n",
    "    scaled_data.append(col)\n",
    "\n",
    "df = pd.DataFrame(np.column_stack(scaled_data), columns=numeric_columns)\n",
    "\n",
    "# Descriptive stats\n",
    "stats = df[numeric_columns].describe().T\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(stats)\n",
    "\n",
    "# Correlation\n",
    "corr = df[numeric_columns].corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(corr.round(2))\n",
    "\n",
    "# Step 4: Categorical columns\n",
    "occupation_categories = ('Salaried/Employed (Private/Public Sector)', 'Agriculturalists (Farmers)', 'Laborers/Skilled Workers', 'Students',  'Homemakers', 'Government Employees (Civil Services, Defense, Police)', 'Self-employed Professionals (Doctors, Lawyers, Chartered Accountants)', 'Retired/Pensioners', 'Business Owners/Entrepreneurs', 'Freelancers/Consultants', 'Unemployed/Jobseekers')\n",
    "occupation_stats = (12.6, 23, 11.4, 19.2, 14.7, 3.2, 3.4, 6, 2.6, 2, 1.9)\n",
    "\n",
    "education_categories = ('Primary or less', 'Secondary', 'Tertiary or more')\n",
    "education_stats = (69.4, 16.4, 14.2)\n",
    "\n",
    "partner_categories = ('Never Married', 'Currently Married', 'Widowed', 'Divorced')\n",
    "partner_stats = (0.39, 0.475, 0.13, 0.005)\n",
    "\n",
    "truecaller_categories = ('Red', 'Blue', 'Golden')\n",
    "truecaller_stats = (0.2, 0.75, 0.05)\n",
    "\n",
    "reviews_categories = ('1 Star', '2 Star', '3 Star', '4 Star', '5 Star')\n",
    "reviews_stats = (4, 6, 5, 45, 40)\n",
    "\n",
    "social_sentiments_categories = ('Strongly Negative', 'Negative', 'Neutral', 'Positive', 'Strongly Positive')\n",
    "social_sentiments_stats = (20, 32, 32, 12, 4)\n",
    "\n",
    "betting_categories = ('Yes', 'No')\n",
    "betting_stats = (0.1, 0.9)\n",
    "\n",
    "family_defaulters_stats=(1, 1, 0, 5, \"continuous\")\n",
    "\n",
    "df['Occupation'] = fabricate.create_categorical_distribution(occupation_categories, occupation_stats, nan_probability=0.01)\n",
    "df['Education'] = fabricate.create_categorical_distribution(education_categories, education_stats, nan_probability=0.01)\n",
    "df['Partner'] = fabricate.create_categorical_distribution(partner_categories, partner_stats, nan_probability=0.01)\n",
    "df['Betting Apps'] = fabricate.create_categorical_distribution(betting_categories, betting_stats, nan_probability=0.01)\n",
    "df['TrueCaller Flag'] = fabricate.create_categorical_distribution(truecaller_categories, truecaller_stats, nan_probability=0.01)\n",
    "df['Reviews received'] = fabricate.create_categorical_distribution(reviews_categories, reviews_stats, nan_probability=0.01)\n",
    "df['Sentiment on Social Media'] = fabricate.create_categorical_distribution(social_sentiments_categories, social_sentiments_stats, nan_probability=0.01)\n",
    "df['Family Defaulter'] = fabricate.create_truncated_norm_distribution(family_defaulters_stats,precision=0,nan_probability=0)\n"
   ],
   "id": "72eb6bbe1d2066fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data2 = df[numeric_columns]  # numeric part\n",
    "categorical_part = df[['Occupation', 'Education', 'Partner',\n",
    "                       'Betting Apps', 'TrueCaller Flag',\n",
    "                       'Reviews received', 'Sentiment on Social Media']]\n",
    "\n",
    "# Reset indexes so they align before concatenating\n",
    "data = data.reset_index(drop=True)\n",
    "data2 = data2.reset_index(drop=True)\n",
    "categorical_part = categorical_part.reset_index(drop=True)\n",
    "\n",
    "# Combine numeric + categorical\n",
    "final_df = pd.concat([data, data2, categorical_part], axis=1)"
   ],
   "id": "5c9c728ac145a92b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_df",
   "id": "20669093430b3f32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_df.to_csv('data/fabricated_data.csv')\n",
    "# preprocess.preprocess_data(final_df)"
   ],
   "id": "35c79506e12572e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_gen = df[numeric_columns].corr().values\n",
    "expected = correlation_matrix.copy()\n",
    "mask = ~np.eye(expected.shape[0], dtype=bool)\n",
    "mae = np.mean(np.abs(corr_gen[mask] - expected[mask]))\n",
    "print(\"MAE (off-diagonals):\", mae)"
   ],
   "id": "551a730e7d99e3f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "analyze.perform_eda(final_df)",
   "id": "99aa4190b1b3557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# analyze.perform_eda(pd.read_csv('data/preprocessed_fabricated_data.csv'))",
   "id": "cd6596ae2324f43",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
